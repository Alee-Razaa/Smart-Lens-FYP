{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Smart Lens v2 - Fine-Tune Existing Model with More Data\n","\n","**Strategy: Transfer Learning from your trained best.pt**\n","\n","This notebook does NOT start from scratch. It loads your trained model and fine-tunes it.\n","\n","### Pipeline:\n","1. Mount Drive & upload best.pt\n","2. Download your existing dataset (Roboflow)\n","3. Download additional open-source datasets for each class\n","4. Merge & deduplicate all datasets into unified YOLOv8 format\n","5. Fine-tune from best.pt with merged dataset\n","6. Evaluate & compare with v1\n","7. Export & download improved model"]},{"cell_type":"markdown","metadata":{},"source":["---\n","## Section 1: Environment Setup"]},{"cell_type":"code","metadata":{},"source":["# 1A: Install dependencies\n","!pip install -q ultralytics roboflow opencv-python-headless\n","\n","import os, shutil, glob, yaml, json, random, time\n","from pathlib import Path\n","from datetime import datetime\n","from collections import Counter\n","\n","import torch\n","print(f'PyTorch: {torch.__version__}')\n","print(f'CUDA available: {torch.cuda.is_available()}')\n","if torch.cuda.is_available():\n","    print(f'GPU: {torch.cuda.get_device_name(0)}')\n","    print(f'VRAM: {torch.cuda.get_device_properties(0).total_mem / 1024**3:.1f} GB')"],"outputs":[],"execution_count":null},{"cell_type":"code","metadata":{},"source":["# 1B: Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","DRIVE_DIR = '/content/drive/MyDrive/Smart-Lens-FYP'\n","os.makedirs(DRIVE_DIR, exist_ok=True)\n","os.makedirs(f'{DRIVE_DIR}/models', exist_ok=True)\n","print(f'Drive directory: {DRIVE_DIR}')"],"outputs":[],"execution_count":null},{"cell_type":"code","metadata":{},"source":["# 1C: Upload your existing best.pt model\n","from google.colab import files\n","\n","MODEL_PATH = '/content/best.pt'\n","drive_model = f'{DRIVE_DIR}/models/best_v1.pt'\n","if os.path.exists(drive_model):\n","    shutil.copy(drive_model, MODEL_PATH)\n","    print(f'Loaded model from Drive: {drive_model}')\n","elif not os.path.exists(MODEL_PATH):\n","    print('Upload your best.pt file:')\n","    uploaded = files.upload()\n","    for name in uploaded:\n","        shutil.move(name, MODEL_PATH)\n","    shutil.copy(MODEL_PATH, drive_model)\n","    print(f'Saved backup to Drive: {drive_model}')\n","\n","print(f'Model ready: {MODEL_PATH} ({os.path.getsize(MODEL_PATH)/1024/1024:.1f} MB)')"],"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{},"source":["---\n","## Section 2: Download & Merge Datasets\n","\n","### How to add additional datasets:\n","1. Go to universe.roboflow.com\n","2. Search for: gun detection, knife detection, fire detection, violence detection\n","3. Pick a dataset (1000+ images, good ratings)\n","4. Click Download Dataset > Format: YOLOv8 > show download code\n","5. Copy workspace, project, version from the code\n","6. Add to ADDITIONAL_DATASETS list in Cell 2B\n","\n","Class IDs: 0=Fighting, 1=Fire, 2=Gun, 3=Knife"]},{"cell_type":"code","metadata":{},"source":["# 2A: Download your ORIGINAL dataset\n","from roboflow import Roboflow\n","\n","rf = Roboflow(api_key='7QsEv54uizzlrvPZ972Z')\n","project = rf.workspace('fpy').project('smart-survellaince-lens-2')\n","version = project.version(1)\n","original_ds = version.download('yolov8', location='/content/datasets/original')\n","print(f'Original dataset downloaded')"],"outputs":[],"execution_count":null},{"cell_type":"code","metadata":{},"source":["# 2B: Download ADDITIONAL open-source datasets\n","# HOW TO ADD: Go to universe.roboflow.com, find a dataset,\n","# click Download > YOLOv8 > show download code,\n","# then copy workspace/project/version into an entry below.\n","#\n","# class_map: maps SOURCE class names to YOUR target class IDs\n","#   Fighting=0, Fire=1, Gun=2, Knife=3\n","\n","ADDITIONAL_DATASETS = [\n","    # UNCOMMENT & EDIT with real values from Roboflow Universe:\n","    #\n","    # {\n","    #     'name': 'Gun Detection Dataset',\n","    #     'workspace': 'paste-workspace-from-download-code',\n","    #     'project': 'paste-project-from-download-code',\n","    #     'version': 1,\n","    #     'class_map': {'handgun': 2, 'gun': 2, 'pistol': 2, 'weapon': 2},\n","    # },\n","    # {\n","    #     'name': 'Knife Detection Dataset',\n","    #     'workspace': 'paste-workspace-from-download-code',\n","    #     'project': 'paste-project-from-download-code',\n","    #     'version': 1,\n","    #     'class_map': {'knife': 3, 'blade': 3},\n","    # },\n","    # {\n","    #     'name': 'Fire Smoke Detection',\n","    #     'workspace': 'paste-workspace-from-download-code',\n","    #     'project': 'paste-project-from-download-code',\n","    #     'version': 1,\n","    #     'class_map': {'fire': 1, 'smoke': 1, 'flame': 1},\n","    # },\n","]\n","\n","downloaded_paths = []\n","for i, ds_info in enumerate(ADDITIONAL_DATASETS):\n","    name = ds_info['name']\n","    print(f'\\n[{i+1}/{len(ADDITIONAL_DATASETS)}] Downloading: {name}...')\n","    try:\n","        rf2 = Roboflow(api_key='7QsEv54uizzlrvPZ972Z')\n","        proj = rf2.workspace(ds_info['workspace']).project(ds_info['project'])\n","        ver = proj.version(ds_info['version'])\n","        dl_path = f'/content/datasets/extra_{i}'\n","        ver.download('yolov8', location=dl_path)\n","        ds_info['local_path'] = dl_path\n","        downloaded_paths.append(ds_info)\n","        n_imgs = len(glob.glob(f'{dl_path}/**/images/*', recursive=True))\n","        print(f'  Done: {n_imgs} images')\n","    except Exception as e:\n","        print(f'  Failed: {e}')\n","        print(f'  Skipping...')\n","\n","if len(ADDITIONAL_DATASETS) == 0:\n","    print('No additional datasets configured.')\n","    print('Fine-tuning on original 1793 images only (still beneficial).')\n","    print('To add more data: see instructions above.')\n","else:\n","    print(f'\\n{len(downloaded_paths)}/{len(ADDITIONAL_DATASETS)} datasets downloaded')"],"outputs":[],"execution_count":null},{"cell_type":"code","metadata":{},"source":["# 2B-ALT: Manual dataset upload (OPTIONAL)\n","import zipfile\n","\n","UPLOAD_DATASETS = False  # Set True to upload ZIP datasets manually\n","\n","if UPLOAD_DATASETS:\n","    print('Upload YOLOv8 dataset ZIP files:')\n","    uploaded = files.upload()\n","    for zip_name in uploaded:\n","        extract_path = f'/content/datasets/uploaded_{Path(zip_name).stem}'\n","        os.makedirs(extract_path, exist_ok=True)\n","        with zipfile.ZipFile(zip_name, 'r') as z:\n","            z.extractall(extract_path)\n","        n = len(glob.glob(f'{extract_path}/**/images/*', recursive=True))\n","        print(f'Extracted {n} images to: {extract_path}')\n","        downloaded_paths.append({\n","            'name': f'Uploaded: {zip_name}',\n","            'local_path': extract_path,\n","            'class_map': {\n","                'gun': 2, 'handgun': 2, 'pistol': 2, 'weapon': 2,\n","                'knife': 3, 'blade': 3,\n","                'fire': 1, 'smoke': 1, 'flame': 1,\n","                'fighting': 0, 'violence': 0, 'fight': 0,\n","            },\n","        })\n","else:\n","    print('Manual upload disabled. Set UPLOAD_DATASETS=True to enable.')"],"outputs":[],"execution_count":null},{"cell_type":"code","metadata":{},"source":["# 2C: MERGE all datasets into one unified dataset\n","MERGED_DIR = '/content/merged_dataset'\n","for s in ['train','valid','test']:\n","    os.makedirs(f'{MERGED_DIR}/{s}/images', exist_ok=True)\n","    os.makedirs(f'{MERGED_DIR}/{s}/labels', exist_ok=True)\n","\n","TARGET_CLASSES = {0: 'Fighting', 1: 'Fire', 2: 'Gun', 3: 'Knife'}\n","stats = {'total_images': 0, 'per_class': Counter(), 'per_source': Counter()}\n","\n","def copy_dataset(src_dir, prefix, class_remap=None, source_data_yaml=None):\n","    src_class_names = {}\n","    if source_data_yaml and os.path.exists(source_data_yaml):\n","        with open(source_data_yaml) as f:\n","            src_yaml = yaml.safe_load(f)\n","            names = src_yaml.get('names', [])\n","            if isinstance(names, list):\n","                src_class_names = {i: n for i, n in enumerate(names)}\n","            elif isinstance(names, dict):\n","                src_class_names = names\n","    copied = 0\n","    for split in ['train', 'valid', 'test']:\n","        img_dir = os.path.join(src_dir, split, 'images')\n","        lbl_dir = os.path.join(src_dir, split, 'labels')\n","        if not os.path.isdir(img_dir): continue\n","        for img_file in glob.glob(os.path.join(img_dir, '*')):\n","            stem = Path(img_file).stem\n","            ext = Path(img_file).suffix\n","            lbl_file = os.path.join(lbl_dir, f'{stem}.txt')\n","            new_name = f'{prefix}_{stem}'\n","            new_img = os.path.join(MERGED_DIR, split, 'images', f'{new_name}{ext}')\n","            new_lbl = os.path.join(MERGED_DIR, split, 'labels', f'{new_name}.txt')\n","            if not os.path.exists(lbl_file): continue\n","            if class_remap and src_class_names:\n","                remapped = []\n","                with open(lbl_file) as f:\n","                    for line in f:\n","                        parts = line.strip().split()\n","                        if len(parts) < 5: continue\n","                        src_id = int(parts[0])\n","                        src_name = src_class_names.get(src_id, '')\n","                        tgt = None\n","                        for k, v in class_remap.items():\n","                            if k.lower() == src_name.lower():\n","                                tgt = v; break\n","                        if tgt is None and src_id in class_remap.values():\n","                            tgt = src_id\n","                        if tgt is not None:\n","                            parts[0] = str(tgt)\n","                            remapped.append(' '.join(parts))\n","                            stats['per_class'][TARGET_CLASSES[tgt]] += 1\n","                if not remapped: continue\n","                shutil.copy2(img_file, new_img)\n","                with open(new_lbl, 'w') as f:\n","                    f.write('\\n'.join(remapped) + '\\n')\n","            else:\n","                shutil.copy2(img_file, new_img)\n","                shutil.copy2(lbl_file, new_lbl)\n","                with open(lbl_file) as f:\n","                    for line in f:\n","                        parts = line.strip().split()\n","                        if parts:\n","                            cid = int(parts[0])\n","                            stats['per_class'][TARGET_CLASSES.get(cid, f'Unk_{cid}')] += 1\n","            copied += 1\n","    return copied\n","\n","print('Copying original dataset...')\n","n = copy_dataset('/content/datasets/original', prefix='orig')\n","stats['per_source']['Original'] = n\n","stats['total_images'] += n\n","print(f'  {n} images from original dataset')\n","\n","for ds_info in downloaded_paths:\n","    name = ds_info['name']\n","    path = ds_info['local_path']\n","    remap = ds_info['class_map']\n","    pfx = name.replace(' ', '_').lower()[:15]\n","    dy = os.path.join(path, 'data.yaml')\n","    print(f'\\nMerging: {name}...')\n","    if os.path.exists(dy):\n","        with open(dy) as f:\n","            print(f'  Source classes: {yaml.safe_load(f).get(\"names\", \"?\")}')\n","    n = copy_dataset(path, prefix=pfx, class_remap=remap, source_data_yaml=dy)\n","    stats['per_source'][name] = n\n","    stats['total_images'] += n\n","    print(f'  {n} images merged')\n","\n","print(f'\\n{\"=\"*60}')\n","print(f'MERGE COMPLETE - Total: {stats[\"total_images\"]} images')\n","print(f'{\"=\"*60}')\n","for src, count in stats['per_source'].items():\n","    print(f'  {src}: {count}')\n","print('Per class:')\n","for cls, count in stats['per_class'].most_common():\n","    print(f'  {cls}: {count}')"],"outputs":[],"execution_count":null},{"cell_type":"code","metadata":{},"source":["# 2D: Re-split and create data.yaml\n","all_train = glob.glob(f'{MERGED_DIR}/train/images/*')\n","all_valid = glob.glob(f'{MERGED_DIR}/valid/images/*')\n","all_test = glob.glob(f'{MERGED_DIR}/test/images/*')\n","print(f'Before: train={len(all_train)} valid={len(all_valid)} test={len(all_test)}')\n","\n","total = len(all_train) + len(all_valid) + len(all_test)\n","tv = int(total * 0.15)\n","tt = int(total * 0.05)\n","if len(all_valid) < tv * 0.5:\n","    print('Redistributing...')\n","    for imgs in [all_valid, all_test]:\n","        for img in imgs:\n","            ext = Path(img).suffix\n","            lbl = img.replace('/images/', '/labels/').replace(ext, '.txt')\n","            shutil.move(img, f'{MERGED_DIR}/train/images/{Path(img).name}')\n","            if os.path.exists(lbl): shutil.move(lbl, f'{MERGED_DIR}/train/labels/{Path(lbl).name}')\n","    ai = glob.glob(f'{MERGED_DIR}/train/images/*')\n","    random.seed(42); random.shuffle(ai)\n","    for imgs, sp in [(ai[:tv], 'valid'), (ai[tv:tv+tt], 'test')]:\n","        for img in imgs:\n","            ext = Path(img).suffix\n","            lbl = img.replace('/images/', '/labels/').replace(ext, '.txt')\n","            shutil.move(img, f'{MERGED_DIR}/{sp}/images/{Path(img).name}')\n","            if os.path.exists(lbl): shutil.move(lbl, f'{MERGED_DIR}/{sp}/labels/{Path(lbl).name}')\n","\n","ft = len(glob.glob(f'{MERGED_DIR}/train/images/*'))\n","fv = len(glob.glob(f'{MERGED_DIR}/valid/images/*'))\n","fte = len(glob.glob(f'{MERGED_DIR}/test/images/*'))\n","print(f'Final: train={ft} valid={fv} test={fte} total={ft+fv+fte}')\n","\n","data_yaml = {'names': ['Fighting','Fire','Gun','Knife'], 'nc': 4,\n","    'train': f'{MERGED_DIR}/train/images',\n","    'val': f'{MERGED_DIR}/valid/images',\n","    'test': f'{MERGED_DIR}/test/images'}\n","data_yaml_path = f'{MERGED_DIR}/data.yaml'\n","with open(data_yaml_path, 'w') as f:\n","    yaml.dump(data_yaml, f, default_flow_style=False)\n","print(f'data.yaml created: {data_yaml_path}')"],"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{},"source":["---\n","## Section 3: Fine-Tune Model from best.pt\n","\n","Key differences from training from scratch:\n","- model = YOLO('best.pt') instead of YOLO('yolov8s.pt')\n","- Lower learning rate (0.0005 vs 0.001)\n","- Fewer epochs (100 vs 200)\n","- Less aggressive augmentation"]},{"cell_type":"code","metadata":{},"source":["# 3A: Configure fine-tuning\n","STRATEGY = 'full'  # 'full' or 'freeze_backbone'\n","\n","FINETUNE_CONFIG = {\n","    'model': MODEL_PATH, 'data': data_yaml_path,\n","    'epochs': 100, 'patience': 30, 'batch': 16, 'imgsz': 640, 'device': 0,\n","    'optimizer': 'AdamW', 'lr0': 0.0005, 'lrf': 0.01,\n","    'weight_decay': 0.0005, 'warmup_epochs': 3,\n","    'hsv_h': 0.015, 'hsv_s': 0.5, 'hsv_v': 0.3,\n","    'degrees': 5.0, 'translate': 0.15, 'scale': 0.4, 'shear': 2.0,\n","    'flipud': 0.0, 'fliplr': 0.5, 'mosaic': 1.0, 'mixup': 0.1,\n","    'copy_paste': 0.1, 'erasing': 0.3, 'close_mosaic': 15,\n","    'freeze': 10 if STRATEGY == 'freeze_backbone' else None,\n","    'dropout': 0.05, 'save': True, 'save_period': 10, 'plots': True,\n","    'project': '/content/runs', 'name': 'smart_lens_v2', 'exist_ok': True,\n","}\n","print(f'Strategy: {STRATEGY} | LR: {FINETUNE_CONFIG[\"lr0\"]} | Epochs: {FINETUNE_CONFIG[\"epochs\"]}')"],"outputs":[],"execution_count":null},{"cell_type":"code","metadata":{},"source":["# 3B: START FINE-TUNING\n","from ultralytics import YOLO\n","\n","model = YOLO(FINETUNE_CONFIG['model'])\n","print(f'Model loaded | Classes: {model.names}')\n","print(f'Starting fine-tuning...\\n')\n","\n","start_time = time.time()\n","train_args = {k: v for k, v in FINETUNE_CONFIG.items() if v is not None and k != 'model'}\n","results = model.train(**train_args)\n","training_time = (time.time() - start_time) / 60\n","print(f'\\nFine-tuning complete! Time: {training_time:.1f} minutes')"],"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{},"source":["---\n","## Section 4: Evaluate & Compare"]},{"cell_type":"code","metadata":{},"source":["# 4A: Validate fine-tuned model\n","from ultralytics import YOLO\n","best_v2_path = '/content/runs/smart_lens_v2/weights/best.pt'\n","model_v2 = YOLO(best_v2_path)\n","metrics_v2 = model_v2.val(data=data_yaml_path, split='val')\n","\n","print(f'\\n{\"=\"*60}')\n","print(f'  v2 Metrics: mAP50={metrics_v2.box.map50:.4f} | mAP50-95={metrics_v2.box.map:.4f}')\n","print(f'  Precision={metrics_v2.box.mp:.4f} | Recall={metrics_v2.box.mr:.4f}')\n","for i, cn in enumerate(TARGET_CLASSES.values()):\n","    if i < len(metrics_v2.box.ap50):\n","        print(f'    {cn}: {metrics_v2.box.ap50[i]:.4f}')\n","print(f'{\"=\"*60}')"],"outputs":[],"execution_count":null},{"cell_type":"code","metadata":{},"source":["# 4B: Compare v1 vs v2\n","v1 = {'mAP50': 0.7255, 'mAP50_95': 0.3322, 'precision': 0.8410, 'recall': 0.6213}\n","v2 = {'mAP50': metrics_v2.box.map50, 'mAP50_95': metrics_v2.box.map,\n","      'precision': metrics_v2.box.mp, 'recall': metrics_v2.box.mr}\n","\n","print(f'\\n{\"Metric\":<15} {\"v1\":>10} {\"v2\":>10} {\"Delta\":>10}')\n","print('-'*50)\n","for k in v1:\n","    d = v2[k] - v1[k]\n","    a = '+' if d > 0 else ''\n","    print(f'{k:<15} {v1[k]:>10.4f} {v2[k]:>10.4f} {a}{d:>9.4f}')\n","\n","if v2['mAP50'] > v1['mAP50']:\n","    print('\\nv2 is BETTER than v1!')\n","else:\n","    print('\\nv2 similar/lower - add more diverse data for bigger gains')"],"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{},"source":["---\n","## Section 5: Export & Save"]},{"cell_type":"code","metadata":{},"source":["# 5A: Export ONNX + Save to Drive\n","model_v2.export(format='onnx', simplify=True)\n","ts = datetime.now().strftime('%Y%m%d_%H%M')\n","odir = f'{DRIVE_DIR}/models/smart_lens_v2_{ts}'\n","os.makedirs(odir, exist_ok=True)\n","shutil.copy(best_v2_path, f'{odir}/best.pt')\n","shutil.copy(best_v2_path.replace('.pt','.onnx'), f'{odir}/best.onnx')\n","shutil.copy('/content/runs/smart_lens_v2/weights/last.pt', f'{odir}/last.pt')\n","\n","md = {'mAP50': float(metrics_v2.box.map50), 'mAP50_95': float(metrics_v2.box.map),\n","      'precision': float(metrics_v2.box.mp), 'recall': float(metrics_v2.box.mr),\n","      'training_time_min': round(training_time, 1), 'base': 'smart_lens_v1',\n","      'strategy': STRATEGY, 'total_images': stats['total_images'],\n","      'classes': list(TARGET_CLASSES.values())}\n","with open(f'{odir}/metrics.json', 'w') as f: json.dump(md, f, indent=2)\n","with open(f'{odir}/training_config.json', 'w') as f: json.dump(FINETUNE_CONFIG, f, indent=2, default=str)\n","\n","print(f'Saved to: {odir}/')\n","for fn in os.listdir(odir):\n","    sz = os.path.getsize(f'{odir}/{fn}') / 1024 / 1024\n","    print(f'  {fn} ({sz:.1f} MB)')"],"outputs":[],"execution_count":null},{"cell_type":"code","metadata":{},"source":["# 5B: Download to local machine\n","from google.colab import files\n","files.download(f'{odir}/best.pt')\n","print('Place in: Smart-Lens-FYP/trained_models/smart_lens_v2_XXXX/best.pt')"],"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{},"source":["---\n","## Section 6: Quick Test"]},{"cell_type":"code","metadata":{},"source":["import matplotlib.pyplot as plt\n","test_imgs = glob.glob(f'{MERGED_DIR}/test/images/*')[:8]\n","fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n","for i, ip in enumerate(axes.flatten()):\n","    if i < len(test_imgs):\n","        r = model_v2.predict(test_imgs[i], conf=0.4, verbose=False)\n","        ip.imshow(r[0].plot()[:,:,::-1])\n","        ip.set_title(Path(test_imgs[i]).stem[:30], fontsize=8)\n","    ip.axis('off')\n","plt.suptitle('Smart Lens v2 - Test Predictions', fontsize=16)\n","plt.tight_layout()\n","plt.savefig(f'{odir}/test_predictions.png', dpi=150)\n","plt.show()"],"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{},"source":["---\n","## Done! Next Steps\n","\n","1. Download best.pt (above or from Google Drive)\n","2. Place in Smart-Lens-FYP/trained_models/smart_lens_v2_XXXX/\n","3. Test: python smart_lens_v2.py --source 0 --model trained_models/smart_lens_v2_XXXX/best.pt\n","\n","### To train v3 with more data:\n","1. Go to universe.roboflow.com\n","2. Find gun/knife/fire/fighting datasets\n","3. Click Download > YOLOv8 > show download code\n","4. Add to Cell 2B ADDITIONAL_DATASETS list\n","5. Upload v2 best.pt as starting model\n","6. Re-run this notebook"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.0"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":4}
